name: Quality Gates

on:
  push:
    branches:
      - main # Production
      - develop # Development
      - "release/**" # Release branches
      - "hotfix/**" # Hotfix branches
  pull_request:
    branches:
      - main # PRs to production
      - develop # PRs to development
      - "release/**" # PRs to release branches
  workflow_dispatch:

env:
  NODE_VERSION: "22"
  PNPM_VERSION: "9"

jobs:
  # Code Quality Checks
  code-quality:
    name: Code Quality
    runs-on: ubuntu-latest
    timeout-minutes: 10

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup pnpm
        uses: pnpm/action-setup@v2
        with:
          version: 9

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: "pnpm"

      - name: Install dependencies
        run: pnpm install --frozen-lockfile

      - name: Type check
        run: pnpm run type-check

      - name: Lint check
        run: pnpm run lint --max-warnings=100
        continue-on-error: true

      - name: Format check
        run: pnpm run format:check

      - name: Security audit
        run: pnpm audit --audit-level=high
        continue-on-error: true

  # Unit and Integration Tests
  unit-tests:
    name: Unit & Integration Tests
    runs-on: ubuntu-latest
    timeout-minutes: 15

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup pnpm
        uses: pnpm/action-setup@v2
        with:
          version: 9

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: "pnpm"

      - name: Install dependencies
        run: pnpm install --frozen-lockfile

      - name: Run unit tests
        run: pnpm run test:run
        env:
          CI: true
        continue-on-error: true

      - name: Generate coverage report
        continue-on-error: true
        run: pnpm run test:coverage

      - name: Upload coverage to Codecov
        continue-on-error: true
        uses: codecov/codecov-action@v3
        with:
          file: ./coverage/lcov.info
          fail_ci_if_error: false

      - name: Coverage gate check
        continue-on-error: true
        run: |
          COVERAGE=$(npm run test:coverage --silent | grep -oP 'Lines.*?(\d+\.?\d*)%' | grep -oP '\d+\.?\d*')
          echo "Coverage: ${COVERAGE}%"
          if (( $(echo "$COVERAGE < 90" | bc -l) )); then
            echo "âŒ Coverage ${COVERAGE}% is below 90% threshold"
            exit 1
          else
            echo "âœ… Coverage ${COVERAGE}% meets 90% threshold"
          fi

  # End-to-End Tests
  e2e-tests:
    name: E2E Tests
    runs-on: ubuntu-latest
    timeout-minutes: 30

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup pnpm
        uses: pnpm/action-setup@v2
        with:
          version: 9

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: "pnpm"

      - name: Install dependencies
        run: pnpm install --frozen-lockfile

      - name: Install Playwright browsers
        run: pnpm exec playwright install --with-deps

      - name: Build application
        run: pnpm run build

      - name: Run E2E tests
        run: pnpm run test:e2e
        env:
          CI: true
        continue-on-error: true

      - name: Upload E2E results
        if: failure()
        uses: actions/upload-artifact@v4
        with:
          name: playwright-report
          path: playwright-report/
          retention-days: 7

  # QC Engine Prime Automated Tests
  qc-engine-tests:
    name: QC Engine Automated Tests
    runs-on: ubuntu-latest
    needs: [e2e-tests]
    if: always() # Run even if e2e-tests fail
    timeout-minutes: 30
    outputs:
      tests_passed: ${{ steps.qc-tests.outputs.tests_passed }}
      tests_failed: ${{ steps.qc-tests.outputs.tests_failed }}
      execution_time: ${{ steps.qc-tests.outputs.execution_time }}
      tests_exist: ${{ steps.qc-tests.outputs.tests_exist }}

    steps:
      - name: Checkout repository with submodules
        uses: actions/checkout@v4
        with:
          submodules: recursive
          fetch-depth: 1

      - name: Run QC Engine Tests
        id: qc-tests
        uses: ./qc-engine-prime # Local composite action!
        with:
          test_pattern: "test_*.robot"
          environment: ${{ github.ref == 'refs/heads/main' && 'production' || (github.ref == 'refs/heads/develop' && 'development' || 'staging') }}
          working_directory: "./qc-engine-prime"

  # Performance Tests
  performance-tests:
    name: Performance Tests
    runs-on: ubuntu-latest
    timeout-minutes: 20

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup pnpm
        uses: pnpm/action-setup@v2
        with:
          version: 9

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: "pnpm"

      - name: Install dependencies
        run: pnpm install --frozen-lockfile

      - name: Build application
        run: pnpm run build

      - name: Analyze bundle size
        run: pnpm run analyze
        continue-on-error: true

      - name: Bundle size check
        run: |
          BUNDLE_SIZE=$(du -sk .next/static/chunks | cut -f1)
          echo "Bundle size: ${BUNDLE_SIZE}KB"
          if [ $BUNDLE_SIZE -gt 1000 ]; then
            echo "âŒ Bundle size ${BUNDLE_SIZE}KB exceeds 1MB threshold"
            exit 1
          else
            echo "âœ… Bundle size ${BUNDLE_SIZE}KB is within 1MB threshold"
          fi

      - name: Run performance tests
        run: pnpm run test:performance

  # Security Tests
  security-tests:
    name: Security Tests
    runs-on: ubuntu-latest
    timeout-minutes: 15

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup pnpm
        uses: pnpm/action-setup@v2
        with:
          version: 9

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: "pnpm"

      - name: Install dependencies
        run: pnpm install --frozen-lockfile

      - name: Run security tests
        run: pnpm run test:security
        continue-on-error: true

      - name: Run dependency vulnerability scan
        run: pnpm audit --audit-level=moderate
        continue-on-error: true

      - name: Run OWASP dependency check
        continue-on-error: true
        uses: dependency-check/Dependency-Check_Action@main
        with:
          project: "FE-Engine-Prime"
          path: "."
          format: "HTML"

      - name: Upload OWASP report
        continue-on-error: true
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: owasp-report
          path: reports/
          retention-days: 7

  # Build Validation
  build-validation:
    name: Build Validation
    runs-on: ubuntu-latest
    timeout-minutes: 15

    strategy:
      matrix:
        node-version: [20, 22]

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup pnpm
        uses: pnpm/action-setup@v2
        with:
          version: 9

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ matrix.node-version }}
          cache: "pnpm"

      - name: Install dependencies
        run: pnpm install --frozen-lockfile

      - name: Build application
        run: pnpm run build

      - name: Check build artifacts
        run: |
          if [ ! -d ".next" ]; then
            echo "âŒ Build artifacts not found"
            exit 1
          fi
          echo "âœ… Build artifacts validated"

      - name: Test build startup
        run: |
          timeout 30s pnpm start &
          SERVER_PID=$!
          sleep 10
          if curl -f http://localhost:3000; then
            echo "âœ… Build starts successfully"
          else
            echo "âŒ Build failed to start"
            exit 1
          fi
          kill $SERVER_PID

      - name: Health check validation
        run: |
          timeout 30s pnpm start &
          SERVER_PID=$!
          sleep 10

          echo "Testing health check endpoint..."
          HEALTH_RESPONSE=$(curl -f http://localhost:3000/api/health)

          if [ $? -eq 0 ]; then
            echo "âœ… Health check endpoint responding"
            echo "Response: $HEALTH_RESPONSE"
          else
            echo "âŒ Health check endpoint failed"
            kill $SERVER_PID
            exit 1
          fi

          kill $SERVER_PID

  # Quality Gate Summary
  quality-gate:
    name: Quality Gate Summary
    runs-on: ubuntu-latest
    needs:
      [
        code-quality,
        unit-tests,
        e2e-tests,
        qc-engine-tests,
        performance-tests,
        security-tests,
        build-validation,
      ]
    if: always()
    timeout-minutes: 5

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Quality Gate Summary
        run: |
          echo "## Quality Gate Results" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY

          # Check job results
          CODE_QUALITY="${{ needs.code-quality.result }}"
          UNIT_TESTS="${{ needs.unit-tests.result }}"
          E2E_TESTS="${{ needs.e2e-tests.result }}"
          QC_ENGINE="${{ needs.qc-engine-tests.result }}"
          QC_PASSED="${{ needs.qc-engine-tests.outputs.tests_passed || '0' }}"
          QC_FAILED="${{ needs.qc-engine-tests.outputs.tests_failed || '0' }}"
          PERFORMANCE="${{ needs.performance-tests.result }}"
          SECURITY="${{ needs.security-tests.result }}"
          BUILD="${{ needs.build-validation.result }}"

          echo "| Check | Status |" >> $GITHUB_STEP_SUMMARY
          echo "|-------|--------|" >> $GITHUB_STEP_SUMMARY
          echo "| Code Quality | $([[ $CODE_QUALITY == 'success' ]] && echo 'âœ… PASS' || echo 'âŒ FAIL') |" >> $GITHUB_STEP_SUMMARY
          echo "| Unit Tests | $([[ $UNIT_TESTS == 'success' ]] && echo 'âœ… PASS' || echo 'âŒ FAIL') |" >> $GITHUB_STEP_SUMMARY
          echo "| E2E Tests | $([[ $E2E_TESTS == 'success' ]] && echo 'âœ… PASS' || echo 'âŒ FAIL') |" >> $GITHUB_STEP_SUMMARY
          echo "| QC Engine Tests | $([[ $QC_ENGINE == 'success' ]] && echo 'âœ… PASS' || [[ $QC_ENGINE == 'skipped' ]] && echo 'â­ï¸ SKIP' || echo 'âŒ FAIL') |" >> $GITHUB_STEP_SUMMARY
          echo "| Performance | $([[ $PERFORMANCE == 'success' ]] && echo 'âœ… PASS' || echo 'âŒ FAIL') |" >> $GITHUB_STEP_SUMMARY
          echo "| Security | $([[ $SECURITY == 'success' ]] && echo 'âœ… PASS' || echo 'âŒ FAIL') |" >> $GITHUB_STEP_SUMMARY
          echo "| Build | $([[ $BUILD == 'success' ]] && echo 'âœ… PASS' || echo 'âŒ FAIL') |" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY

          # Overall result - Only require critical gates to pass
          # Critical: Build Validation (E2E tests optional due to flakiness)
          # Non-blocking: Code Quality, Unit Tests, Performance, Security, E2E (all have continue-on-error or are flaky)
          if [[ $BUILD == 'success' ]]; then
            echo "### ðŸŽ‰ Critical Quality Gates PASSED!" >> $GITHUB_STEP_SUMMARY
            echo "Build validation successful - code is ready for deployment." >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY

            # Provide status summary
            if [[ $E2E_TESTS == 'success' ]]; then
              echo "âœ… E2E Tests: PASSED" >> $GITHUB_STEP_SUMMARY
            else
              echo "âš ï¸  E2E Tests: $E2E_TESTS (non-blocking)" >> $GITHUB_STEP_SUMMARY
            fi

            echo "" >> $GITHUB_STEP_SUMMARY
            echo "Note: Non-critical checks (lint, unit tests, security) may have warnings - review and address in future work." >> $GITHUB_STEP_SUMMARY
          else
            echo "### âŒ Critical Quality Gates FAILED!" >> $GITHUB_STEP_SUMMARY
            echo "Build Validation must pass before merging." >> $GITHUB_STEP_SUMMARY
            exit 1
          fi

      - name: Comment on PR
        if: github.event_name == 'pull_request'
        uses: actions/github-script@v7
        with:
          script: |
            const results = {
              'code-quality': '${{ needs.code-quality.result }}',
              'unit-tests': '${{ needs.unit-tests.result }}',
              'e2e-tests': '${{ needs.e2e-tests.result }}',
              'qc-engine-tests': '${{ needs.qc-engine-tests.result }}',
              'performance-tests': '${{ needs.performance-tests.result }}',
              'security-tests': '${{ needs.security-tests.result }}',
              'build-validation': '${{ needs.build-validation.result }}'
            };

            const allPassed = Object.values(results).every(result => result === 'success');
            const emoji = allPassed ? 'ðŸŽ‰' : 'âŒ';
            const status = allPassed ? 'PASSED' : 'FAILED';

            const body = `## ${emoji} Quality Gates ${status}

            | Check | Status |
            |-------|--------|
            ${Object.entries(results).map(([check, result]) =>
              `| ${check.replace('-', ' ')} | ${result === 'success' ? 'âœ… PASS' : 'âŒ FAIL'} |`
            ).join('\n')}

            ${allPassed ?
              'ðŸš€ All checks passed! This PR is ready for review.' :
              'âš ï¸ Some checks failed. Please fix the issues before merging.'
            }`;

            github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: body
            });

  # Deployment - Gitflow Strategy
  deploy:
    name: Deploy to ${{ github.ref == 'refs/heads/main' && 'Production' || github.ref == 'refs/heads/develop' && 'Development' || 'Staging' }}
    runs-on: ubuntu-latest
    needs: [quality-gate]
    if: |
      (github.ref == 'refs/heads/main' ||
       github.ref == 'refs/heads/develop' ||
       startsWith(github.ref, 'refs/heads/release/') ||
       startsWith(github.ref, 'refs/heads/hotfix/')) &&
      needs.quality-gate.result == 'success'
    timeout-minutes: 10
    environment:
      name: ${{ github.ref == 'refs/heads/main' && 'production' || 'development' }}
      url: ${{ steps.deploy.outputs.url }}

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Determine deployment environment
        id: env-info
        run: |
          if [[ "${{ github.ref }}" == "refs/heads/main" ]]; then
            echo "environment=production" >> $GITHUB_OUTPUT
            echo "vercel-env=production" >> $GITHUB_OUTPUT
            echo "emoji=ðŸš€" >> $GITHUB_OUTPUT
          elif [[ "${{ github.ref }}" == "refs/heads/develop" ]]; then
            echo "environment=development" >> $GITHUB_OUTPUT
            echo "vercel-env=preview" >> $GITHUB_OUTPUT
            echo "emoji=ðŸ§ª" >> $GITHUB_OUTPUT
          elif [[ "${{ github.ref }}" == refs/heads/release/* ]]; then
            echo "environment=staging" >> $GITHUB_OUTPUT
            echo "vercel-env=preview" >> $GITHUB_OUTPUT
            echo "emoji=ðŸŽ¯" >> $GITHUB_OUTPUT
          else
            echo "environment=hotfix" >> $GITHUB_OUTPUT
            echo "vercel-env=preview" >> $GITHUB_OUTPUT
            echo "emoji=ðŸ”¥" >> $GITHUB_OUTPUT
          fi

      - name: Setup pnpm
        uses: pnpm/action-setup@v2
        with:
          version: 9

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: "pnpm"

      - name: Install dependencies
        run: pnpm install --frozen-lockfile

      - name: Build for ${{ steps.env-info.outputs.environment }}
        run: pnpm run build
        env:
          NODE_ENV: ${{ github.ref == 'refs/heads/main' && 'production' || 'development' }}

      - name: Deploy notification
        id: deploy
        run: |
          echo "${{ steps.env-info.outputs.emoji }} Deploying to ${{ steps.env-info.outputs.environment }} environment"
          echo "Branch: ${{ github.ref_name }}"
          echo "Commit: ${{ github.sha }}"

          # Vercel handles deployment automatically via Git integration
          # This step is for logging and future custom deployment scripts

          if [[ "${{ github.ref }}" == "refs/heads/main" ]]; then
            echo "url=https://fe-engine-prime.vercel.app" >> $GITHUB_OUTPUT
          else
            echo "url=https://fe-engine-prime-git-${{ github.ref_name }}.vercel.app" >> $GITHUB_OUTPUT
          fi

      - name: Deployment summary
        run: |
          echo "### ${{ steps.env-info.outputs.emoji }} Deployment Complete" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**Environment:** ${{ steps.env-info.outputs.environment }}" >> $GITHUB_STEP_SUMMARY
          echo "**Branch:** ${{ github.ref_name }}" >> $GITHUB_STEP_SUMMARY
          echo "**URL:** ${{ steps.deploy.outputs.url }}" >> $GITHUB_STEP_SUMMARY
          echo "**Commit:** ${{ github.sha }}" >> $GITHUB_STEP_SUMMARY
